# Unity-Motion-Evaluation-Framework
Core algorithms of a VR-based motion learning support system that considers individual differences.  (個人差を考慮したVRベース動作学習支援システムのコアアルゴリズム)
## 概要 (Overview)
このリポジトリは、卒業研究「個人差を考慮したVRベースの全身動作学習支援システム」で開発したコア機能のサンプルコードです。 

主な機能は以下の2点です。
- **体格差補正アルゴリズム:** 学習者とお手本動作の提供者の体格差（身長、腕や脚の長さ）を吸収し、お手本動作を学習者の体格に合わせてリアルタイムで正規化します。 
- **一致性評価アルゴリズム:** 2つの動作の位置・回転誤差を計算し、動作の一致度を定量的にスコア化します。 

## デモ (Demonstration)
実際のシステムでは、お手本動作（緑のボーン）とユーザーの動作（白のボーン）を比較し、誤差のある部位をリアルタイムで色付けしてフィードバックします。 

*(ここに論文の図6.7や図6.9のような、動作の様子がわかるGIFアニメーションや動画へのリンクを貼ることを強くお勧めします。PCの画面録画機能などで簡単に作成できます。)*

![demo-gif](https://github.com/pokujiro/Unity-Motion-Evaluation-Framework/assets/demo.png)  

## 技術的ハイライト (Technical Highlights)
### 1. 体格差補正 (論文 6.3.2章)
ユーザー間の公平な評価を実現するため、キャリブレーションで得たTポーズのデータから、身長($r_h$)、腕($r_a$)、脚($r_l$)の比率を算出します。  これらの比率を用いて、お手本動作の各トラッカー座標を線形に変換し、学習者の体格にリアルタイムでスケーリングします。

### 2. 一致性評価 (論文 6.4.2章)
- **誤差計算:** 各ボーンの位置誤差($E_{pos}$)と回転誤差($E_{rot}$)を、それぞれユークリッド距離と四元数の角度差として計算します。 
- **閾値処理:** 微小なズレをノイズとして無視するため、計算された誤差に閾値を設定し、一定以下の誤差は0として扱います。 
- **スコアリング:** 最終的な一致度スコア`S`は、位置と回転の平均誤差に重み($w_{pos}, w_{rot}$)を付けて算出します。 
  ```csharp
  S = 1 - (w_pos * mean(E_pos) + w_rot * mean(E_rot));
